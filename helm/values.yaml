# Default values for cass-cdc-pg
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Override chart name
nameOverride: ""
fullnameOverride: ""

# Global settings
global:
  # Image registry for all images (optional override)
  imageRegistry: ""
  # Image pull secrets for private registries
  imagePullSecrets: []
  # Storage class for persistent volumes
  storageClass: ""

# Kafka Connect configuration
kafkaConnect:
  # Number of Kafka Connect worker replicas
  replicaCount: 3

  image:
    repository: confluentinc/cp-kafka-connect
    tag: "7.5.2"
    pullPolicy: IfNotPresent

  # Resource limits and requests
  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 1Gi

  # Liveness and readiness probes
  livenessProbe:
    enabled: true
    httpGet:
      path: /
      port: 8083
    initialDelaySeconds: 60
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3

  readinessProbe:
    enabled: true
    httpGet:
      path: /
      port: 8083
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

  # Service configuration
  service:
    type: ClusterIP
    port: 8083
    annotations: {}

  # Horizontal Pod Autoscaler
  autoscaling:
    enabled: false
    minReplicas: 3
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

  # Pod affinity and anti-affinity
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                    - kafka-connect
            topologyKey: kubernetes.io/hostname

  # Node selector
  nodeSelector: {}

  # Tolerations
  tolerations: []

  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000

  # Environment variables for Kafka Connect
  env:
    # Kafka broker connection
    CONNECT_BOOTSTRAP_SERVERS: "kafka-broker:9092"
    CONNECT_REST_PORT: "8083"
    CONNECT_GROUP_ID: "cdc-connect"

    # Topic configuration for Kafka Connect internal topics
    CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
    CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
    CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
    CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "3"
    CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "3"
    CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "3"

    # Converters
    CONNECT_KEY_CONVERTER: "io.confluent.connect.avro.AvroConverter"
    CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
    CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
    CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
    CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
    CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"

    # Internal converters
    CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
    CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"

    # Connect settings
    CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
    CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

    # Producer and consumer overrides for better performance
    CONNECT_PRODUCER_COMPRESSION_TYPE: "lz4"
    CONNECT_PRODUCER_BATCH_SIZE: "32768"
    CONNECT_PRODUCER_LINGER_MS: "10"
    CONNECT_CONSUMER_MAX_POLL_RECORDS: "1000"
    CONNECT_CONSUMER_MAX_POLL_INTERVAL_MS: "300000"

    # Task configuration
    CONNECT_TASK_SHUTDOWN_GRACEFUL_TIMEOUT_MS: "30000"
    CONNECT_OFFSET_FLUSH_INTERVAL_MS: "10000"

    # Logging
    CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
    CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"

  # Custom environment variables from secrets
  envFrom:
    - secretRef:
        name: cdc-vault-token

# Connector configurations
connectors:
  # Cassandra Source Connector
  cassandraSource:
    enabled: true
    name: "cassandra-source-connector"
    config:
      connector.class: "io.debezium.connector.cassandra.CassandraConnector"
      tasks.max: "1"
      cassandra.hosts: "cassandra-cluster:9042"
      cassandra.username: "${file:/vault/secrets/cassandra:username}"
      cassandra.password: "${file:/vault/secrets/cassandra:password}"
      cassandra.keyspace: "warehouse"
      cassandra.table.include.list: "warehouse.users,warehouse.orders"
      kafka.topic.prefix: "cdc-events"
      snapshot.mode: "initial"
      tombstones.on.delete: "true"
      max.batch.size: "2048"
      max.queue.size: "8192"
      offset.storage.topic: "connect-offsets"
      schema.registry.url: "http://schema-registry:8081"

  # PostgreSQL Sink Connector
  postgresqlSink:
    enabled: true
    name: "postgresql-sink-connector"
    config:
      connector.class: "io.confluent.connect.jdbc.JdbcSinkConnector"
      tasks.max: "3"
      connection.url: "jdbc:postgresql://postgres:5432/warehouse?sslmode=require"
      connection.user: "${file:/vault/secrets/postgres:username}"
      connection.password: "${file:/vault/secrets/postgres:password}"
      topics.regex: "cdc-events.*"
      auto.create: "true"
      auto.evolve: "true"
      insert.mode: "upsert"
      pk.mode: "record_key"
      delete.enabled: "true"
      batch.size: "1000"
      max.retries: "10"
      retry.backoff.ms: "1000"
      errors.tolerance: "all"
      errors.deadletterqueue.topic.name: "dlq-events"
      errors.deadletterqueue.context.headers.enable: "true"
      errors.log.enable: "true"
      errors.log.include.messages: "true"

# Vault integration for secrets
vault:
  # Enable Vault integration
  enabled: true

  # Vault server address
  address: "https://vault.vault.svc.cluster.local:8200"

  # Vault authentication method (kubernetes, approle, token)
  authMethod: "kubernetes"

  # Kubernetes auth configuration
  kubernetesAuth:
    role: "cdc-pipeline"
    serviceAccount: "kafka-connect"

  # Vault paths for secrets
  secrets:
    cassandra:
      path: "secret/data/cdc/cassandra"
      keys:
        - username
        - password
    postgres:
      path: "database/creds/postgresql-writer"
      keys:
        - username
        - password
    kafka:
      path: "secret/data/cdc/kafka"
      keys:
        - username
        - password

  # Agent sidecar configuration
  agent:
    enabled: true
    image:
      repository: vault
      tag: "1.15.4"
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 64Mi

# Monitoring and observability
monitoring:
  # Prometheus metrics
  prometheus:
    enabled: true
    port: 8083
    path: "/metrics"
    interval: "30s"

    # ServiceMonitor for Prometheus Operator
    serviceMonitor:
      enabled: true
      namespace: monitoring
      labels:
        release: prometheus

  # Grafana dashboards
  grafana:
    enabled: true
    dashboards:
      - name: kafka-connect-dashboard
        configMap: cdc-grafana-dashboard

# ConfigMaps for connector configurations
configMaps:
  connectors:
    enabled: true
    # Connector JSON files will be mounted here
    mountPath: /etc/kafka-connect/connectors

# Secrets
secrets:
  # Vault token secret (if using token auth)
  vaultToken:
    name: cdc-vault-token
    # Set this in your CI/CD or manually create the secret
    # token: ""

# Service Account
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations:
    # For Vault Kubernetes auth
    vault.hashicorp.com/role: "cdc-pipeline"
  # The name of the service account to use.
  name: "kafka-connect"

# Network policies
networkPolicy:
  enabled: false
  ingress:
    - from:
      - podSelector:
          matchLabels:
            app.kubernetes.io/name: cdc-api
      ports:
      - protocol: TCP
        port: 8083
  egress:
    - to:
      - podSelector:
          matchLabels:
            app.kubernetes.io/name: kafka
      ports:
      - protocol: TCP
        port: 9092
    - to:
      - podSelector:
          matchLabels:
            app.kubernetes.io/name: schema-registry
      ports:
      - protocol: TCP
        port: 8081

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2
  # maxUnavailable: 1

# Extra volumes and volume mounts
extraVolumes: []
  # - name: custom-transforms
  #   configMap:
  #     name: kafka-connect-transforms

extraVolumeMounts: []
  # - name: custom-transforms
  #   mountPath: /opt/transforms
  #   readOnly: true

# Init containers
initContainers: []
  # - name: wait-for-kafka
  #   image: busybox:1.36
  #   command: ['sh', '-c', 'until nc -z kafka-broker 9092; do echo waiting for kafka; sleep 2; done;']

# Annotations for pods
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8083"
  prometheus.io/path: "/metrics"
  vault.hashicorp.com/agent-inject: "true"
  vault.hashicorp.com/role: "cdc-pipeline"

# Labels for pods
podLabels:
  app.kubernetes.io/component: "kafka-connect"
  app.kubernetes.io/part-of: "cdc-pipeline"

# Update strategy
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 0

# Priority class
priorityClassName: ""

# DNS configuration
dnsPolicy: ClusterFirst
dnsConfig: {}

# Host aliases
hostAliases: []

# Lifecycle hooks
lifecycle: {}
  # preStop:
  #   exec:
  #     command: ["/bin/sh", "-c", "sleep 30"]
